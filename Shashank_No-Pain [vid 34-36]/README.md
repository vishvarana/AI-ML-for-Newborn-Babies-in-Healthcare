**Related Issue**

Shashank_No-Pain [vid 34-36] #23

**AI-ML-for-Newborn-Babies-in-Healthcare**

**Predict The Babies Pain By Facial Expression**


**PURPOSE**

Babies can't express his/her pain by verbal so that here we are researching how to predict wheather baby feeling pain or not.


**DATASET**

[Dataset Link](https://livemissouristate-my.sharepoint.com/personal/nyc10040_missouristate_edu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fnyc10040%5Fmissouristate%5Fedu%2FDocuments%2FICOPEvid&originalPath=aHR0cHM6Ly9saXZlbWlzc291cmlzdGF0ZS1teS5zaGFyZXBvaW50LmNvbS86ZjovZy9wZXJzb25hbC9ueWMxMDA0MF9taXNzb3VyaXN0YXRlX2VkdS9FdjJHQ0x1WFJLMURzZ2JlaVJHUnl3a0JCekxMcVJILU9LYU1pM3JGSHVNM2lBP3J0aW1lPWQxVmExS0pHMlVn)


**DESCRIPTION**

For making this reasearch more valuble we are using Opencv Python and extracting images from several videos.
For making this reasearch more valuble we are using Opencv Python and extracting images from several videos. By this research project we can easily find out about babies health condition


**WHAT I HAD DONE**

* Downloaded Video dataset from given drive link in ZIP format
* After then i have used No-Pain and pain folder as per our requirement.
* Extracted almost 50 images from a single video and saved it in separate folder. this task is continuing with other videos.
* After extracting images I have converted that images are in GrayScale format.
* After extracting *_RGB_* images, I have converted that images are in *_GrayScale_* format.


**WORKFLOW OF YOUR PROJECT FILES**

I have added two folders and one Readme file. in my two folders these things are availible:
* Approached Code in .py format
* Extracetd images folder in sub-folder
* No-mild Pain
* Moderate pain
* Severe


**STATE YOUR PROCEDURE AND UNDERSTANDING FROM YOUR WORK**

I have used cv2 library for reading images from videos. I have used os for making path in my local system directory.
I have learned how to extract images from videos.
I have learned how to extract images in RGB format from videos and convert it into GrayScale image.


**LIBRARIES NEEDED**

* cv2
* os 
* glob


**COMPILATION STEPS**

I've spent the last hour or two tried to compile it on Windows, so that I can access these features.

Here's what I learned:
* Requires glob installed globally and on the PATH.
* Requires os on the path.
* I got it working with opencv-python	4.5.3.56


**RESEARCH**

We will predict that the new born babies are feeling pain or they have no pain are they are feeling severe. Overall I have reached to this conclusion:

There are three types of facial expressions happenning:
* Some babies are feeling moderate pain and those facial expressions are something chnage with body gestures.
* Some babies are feeling mild pain and thos facial expressions are something change but those body gestures are not changing.
* SOme babies are severing due to this those body gestures getting close.

So from this research we will be able to find out the babies current feelings/ situation.


**SCREENSHOTS**

*_Moderate Pain_*
![](Image%20Dataset/Moderate%20Pain/12.jpg)


*_No-Mild Pain_*
![](Image%20Dataset/No-Mild%20Pain/108.jpg)


**CONCLUSION**

We will predict that the new born babies are feeling pain or they have no pain are they are feeling severe. Overall I have reached to this conclusion:

There are three types of facial expressions happenning:
* Some babies are feeling moderate pain and those facial expressions are something chnage with body gestures.
* Some babies are feeling mild pain and thos facial expressions are something change but those body gestures are not changing.
* SOme babies are severing due to this those body gestures getting close.

So from this research we will be able to find out the babies current feelings/ situation.



**REFERENCES**

[Link 1](https://www.geeksforgeeks.org/extract-images-from-video-in-python/)
[Link 2](https://www.geeksforgeeks.org/python-process-images-of-a-video-using-opencv/?ref=rp)


**NAME OF AUTHOR**

Shashank Shukla
[Connect with me at here!](https://www.linkedin.com/in/shashankshukla02/)


**DISCLAIMER, IF ANY**

As it is open source contribution so anyone can give feedback on this process or free to use.


